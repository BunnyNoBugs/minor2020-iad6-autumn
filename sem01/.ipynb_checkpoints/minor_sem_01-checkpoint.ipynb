{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вступление\n",
    "\n",
    "Всем привет! На сегодняшнем семинаре мы познакомимся с библиотекой **pytorch**. Он очень похож на numpy, с одним лишь отличием (на самом деле их больше, но сейчас мы поговорим про самое главное) -- pytorch может считать градиенты за вас. Таким образом вам не надо будет руками писать обратный проход в нейросетях. \n",
    "\n",
    "#### Семинар построен следующим образом:\n",
    "\n",
    "1. Вспоминаем numpy и сравниваем операции в pytorch\n",
    "2. Создаем тензоры в pytorch\n",
    "3. Работаем с градиентами руками\n",
    "4. Моя первая нейросеть "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вспоминаем numpy и сравниваем операции в pytorch\n",
    "\n",
    "Мы можем создавать матрицы, перемножать их, складывать, транспонировать и в целом совершать любые матричные операции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.74003135, 0.16182006, 0.24900101],\n",
       "       [0.90932392, 0.34120484, 0.74746697],\n",
       "       [0.67486671, 0.63043883, 0.62021046],\n",
       "       [0.08663312, 0.57330265, 0.46946858],\n",
       "       [0.01800921, 0.97796656, 0.71778168]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.rand(5, 3) # создали случайную матрицу \n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Проверили размеры : (5, 3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Проверили размеры : %s\\n\" % (a.shape,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Добавили 5 :\n",
      "[[5.18708646 5.01249179 5.12438991]\n",
      " [5.7348387  5.49290342 5.74318588]\n",
      " [5.0382025  5.02803045 5.17790168]\n",
      " [5.76357972 5.22294138 5.49249553]\n",
      " [5.79373807 5.84362568 5.56907378]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Добавили 5 :\\n%s\\n\" % (a + 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X*X^T  :\n",
      "[[0.05063024 0.23608045 0.0296265  0.20690184 0.22982308]\n",
      " [0.23608045 1.33526695 0.174103   1.03701222 1.42202303]\n",
      " [0.0296265  0.174103   0.03389414 0.12303558 0.15520917]\n",
      " [0.20690184 1.03701222 0.12303558 0.8753087  1.07442766]\n",
      " [0.22982308 1.42202303 0.15520917 1.07442766 1.66556938]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"X*X^T  :\\n%s\\n\" % np.dot(a, a.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее по колонкам :\n",
      "[0.10798939 0.656976   0.08137821 0.49300554 0.73547918]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Среднее по колонкам :\\n%s\\n\" % (a.mean(axis=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Изменили размеры :\n",
      "(3, 5)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Изменили размеры :\\n%s\\n\" % (a.reshape(3, 5).shape,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогичные операции в **pytorch** выглядят следующим образом, синтаксис отличается, но совсем немного:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2680e+00,  6.6253e-01, -4.1589e-01],\n",
       "        [-1.6051e+00,  8.1909e-01,  1.9392e+00],\n",
       "        [ 1.1126e+00, -1.2598e+00,  3.4418e-01],\n",
       "        [ 1.4927e-03,  2.0393e+00,  7.4301e-01],\n",
       "        [-7.6081e-01,  7.5492e-01, -6.0866e-02]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(5, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Проверили размеры : torch.Size([5, 3])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Проверили размеры : %s\\n\" % (x.shape,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Добавили 5 :\n",
      "tensor([[5.7677, 4.5498, 4.7220],\n",
      "        [2.8459, 5.1555, 7.4199],\n",
      "        [4.8439, 4.2998, 5.3268],\n",
      "        [4.0951, 5.8207, 4.9764],\n",
      "        [3.4637, 4.8489, 2.7013]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Добавили 5 :\\n%s\\n\" % (x + 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X*X^T  (1):\n",
      "tensor([[ 0.8694, -2.3965,  0.1045, -1.0577, -0.4723],\n",
      "        [-2.3965, 10.5200,  1.0183,  2.0198, -2.2767],\n",
      "        [ 0.1045,  1.0183,  0.6214, -0.4410, -0.4056],\n",
      "        [-1.0577,  2.0198, -0.4410,  1.4928,  1.3202],\n",
      "        [-0.4723, -2.2767, -0.4056,  1.3202,  7.6668]])\n",
      "\n",
      "X*X^T  (2):\n",
      "tensor([[ 0.8694, -2.3965,  0.1045, -1.0577, -0.4723],\n",
      "        [-2.3965, 10.5200,  1.0183,  2.0198, -2.2767],\n",
      "        [ 0.1045,  1.0183,  0.6214, -0.4410, -0.4056],\n",
      "        [-1.0577,  2.0198, -0.4410,  1.4928,  1.3202],\n",
      "        [-0.4723, -2.2767, -0.4056,  1.3202,  7.6668]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"X*X^T  (1):\\n%s\\n\" % (torch.matmul(x, x.transpose(1, 0))))\n",
    "print(\"X*X^T  (2):\\n%s\\n\" % (x.mm(x.t())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8694, -2.3965,  0.1045, -1.0577, -0.4723],\n",
       "        [-2.3965, 10.5200,  1.0183,  2.0198, -2.2767],\n",
       "        [ 0.1045,  1.0183,  0.6214, -0.4410, -0.4056],\n",
       "        [-1.0577,  2.0198, -0.4410,  1.4928,  1.3202],\n",
       "        [-0.4723, -2.2767, -0.4056,  1.3202,  7.6668]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x @ x.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_np = x.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.8694165 , -2.3964942 ,  0.10451224, -1.0576502 , -0.47232616],\n",
       "       [-2.3964942 , 10.519975  ,  1.0183275 ,  2.0197725 , -2.2767208 ],\n",
       "       [ 0.10451224,  1.0183275 ,  0.62140214, -0.4409993 , -0.40555346],\n",
       "       [-1.0576502 ,  2.0197725 , -0.4409993 ,  1.4928418 ,  1.3202419 ],\n",
       "       [-0.47232616, -2.2767208 , -0.40555346,  1.3202419 ,  7.666754  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_np @ x_np.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.8694165 , -2.3964942 ,  0.10451224, -1.0576502 , -0.47232616],\n",
       "       [-2.3964942 , 10.519975  ,  1.0183275 ,  2.0197725 , -2.2767208 ],\n",
       "       [ 0.10451224,  1.0183275 ,  0.62140214, -0.4409993 , -0.40555346],\n",
       "       [-1.0576502 ,  2.0197725 , -0.4409993 ,  1.4928418 ,  1.3202419 ],\n",
       "       [-0.47232616, -2.2767208 , -0.40555346,  1.3202419 ,  7.666754  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(x_np, x_np.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее по колонкам :\n",
      "tensor([ 0.0132,  0.1404, -0.1765, -0.0359, -1.3287])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Среднее по колонкам :\\n%s\\n\" % (x.mean(dim=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Изменили размеры :\n",
      "torch.Size([3, 5])\n",
      "\n",
      "Изменили размеры :\n",
      "torch.Size([3, 5])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Изменили размеры :\\n%s\\n\" % (x.view([3, 5]).shape,))\n",
    "print(\"Изменили размеры :\\n%s\\n\" % (x.view_as(x.t()).shape,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Небольшой пример того, как меняются операции:\n",
    "\n",
    "* `x.reshape([1,2,8]) -> x.view(1,2,8)`\n",
    "\n",
    "* `x.sum(axis=-1) -> x.sum(dim=-1)`\n",
    "\n",
    "* `x.astype('int64') -> x.type(torch.LongTensor)`\n",
    "\n",
    "Для помощи вам есть [таблица](https://github.com/torch/torch7/wiki/Torch-for-Numpy-users), которая поможет вам найти аналог операции в numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создаем тензоры в pytorch и снова изучаем базовые операции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1112e-38, 9.5511e-39, 1.0102e-38],\n",
      "        [1.0286e-38, 1.0194e-38, 9.6429e-39],\n",
      "        [9.2755e-39, 9.1837e-39, 9.3674e-39],\n",
      "        [1.0745e-38, 1.0653e-38, 9.5510e-39],\n",
      "        [1.0561e-38, 1.0194e-38, 1.1112e-38]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(5, 3) # пустой тензор\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.44462055e-311,  1.44490144e-311,  9.05282602e-043, ...,\n",
       "         6.95219765e-310,  1.44489562e-311,  1.44295714e-311],\n",
       "       [ 6.95219765e-310,  1.44489562e-311,  1.44295714e-311, ...,\n",
       "        -1.63924593e+205,  1.44487081e-311,  1.44487083e-311],\n",
       "       [-4.79327139e+253,  1.44487081e-311,  1.44487083e-311, ...,\n",
       "         1.44487123e-311,  1.44487127e-311,  2.46960912e-151],\n",
       "       ...,\n",
       "       [ 1.44488628e-311,  1.61638575e-202,  1.44488628e-311, ...,\n",
       "        -2.61407855e+216,  1.44488665e-311,  1.44488674e-311],\n",
       "       [-1.60065044e-010,  1.44488665e-311,  1.44488671e-311, ...,\n",
       "         1.44488800e-311,  1.44488806e-311,  7.50821831e-147],\n",
       "       [ 1.44488807e-311,  1.44488807e-311, -2.35163244e-132, ...,\n",
       "         1.44488832e-311,  7.99371459e+183,  1.44488831e-311]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    np.empty((100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7392, 0.9814, 0.9766],\n",
      "        [0.5003, 0.1951, 0.5352],\n",
      "        [0.5172, 0.1318, 0.0937],\n",
      "        [0.3752, 0.6137, 0.6527],\n",
      "        [0.4122, 0.7658, 0.3286]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3) # тензор со случайными числами\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5, 3) # тензор с нулями\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5, 3, dtype=torch.long) # тензор с нулями и указанием типов чисел\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([5.5, 3]) # конструируем тензор из питоновского листа\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([5.5, 3], dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64) torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "x = x.new_ones(5, 3, dtype=torch.double) # используем уже созданный тензор для создания тензора из единичек\n",
    "print(x, x.size()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1610, -0.6154,  0.4468],\n",
      "        [-0.6242,  0.0245, -0.8571],\n",
      "        [ 1.5801, -0.8821, -0.7437],\n",
      "        [ 0.4104, -0.7644, -0.3790],\n",
      "        [-0.5324, -0.1660, -0.9890]]) torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn_like(x, dtype=torch.float) # создаем матрицу с размерами как у x\n",
    "print(x, x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1185, -0.2987,  0.5967],\n",
      "        [-0.0577,  0.5519, -0.2136],\n",
      "        [ 2.1034, -0.7864, -0.0766],\n",
      "        [ 0.8939, -0.7246,  0.4593],\n",
      "        [-0.2281,  0.1581, -0.7084]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(5, 3)\n",
    "print(x + y) # операция сложение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1185, -0.2987,  0.5967],\n",
      "        [-0.0577,  0.5519, -0.2136],\n",
      "        [ 2.1034, -0.7864, -0.0766],\n",
      "        [ 0.8939, -0.7246,  0.4593],\n",
      "        [-0.2281,  0.1581, -0.7084]])\n"
     ]
    }
   ],
   "source": [
    "z = torch.add(x, y) # очередная операция сложения\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1185, -0.2987,  0.5967],\n",
      "        [-0.0577,  0.5519, -0.2136],\n",
      "        [ 2.1034, -0.7864, -0.0766],\n",
      "        [ 0.8939, -0.7246,  0.4593],\n",
      "        [-0.2281,  0.1581, -0.7084]])\n"
     ]
    }
   ],
   "source": [
    "torch.add(x, y, out=z) # и наконец последний вид\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1542, -0.1949,  0.0670],\n",
      "        [-0.3536,  0.0129, -0.5516],\n",
      "        [ 0.8268, -0.0844, -0.4962],\n",
      "        [ 0.1984, -0.0305, -0.3177],\n",
      "        [-0.1620, -0.0538, -0.2775]])\n"
     ]
    }
   ],
   "source": [
    "print(x * y) # поэлементное умножение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0263,  0.0542,  0.3235,  0.4278, -0.0251],\n",
      "        [-0.7184, -0.8922, -0.8961, -1.0193, -0.4225],\n",
      "        [ 1.1220, -0.0488,  0.2463,  0.1053, -0.0138],\n",
      "        [ 0.0941, -0.4146, -0.1112, -0.1498, -0.2292],\n",
      "        [-0.7107, -1.0257, -0.9544, -1.0931, -0.4933]])\n"
     ]
    }
   ],
   "source": [
    "print(x @ y.t()) # матричное умножение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0263,  0.0542,  0.3235,  0.4278, -0.0251],\n",
      "        [-0.7184, -0.8922, -0.8961, -1.0193, -0.4225],\n",
      "        [ 1.1220, -0.0488,  0.2463,  0.1053, -0.0138],\n",
      "        [ 0.0941, -0.4146, -0.1112, -0.1498, -0.2292],\n",
      "        [-0.7107, -1.0257, -0.9544, -1.0931, -0.4933]])\n"
     ]
    }
   ],
   "source": [
    "print(x.mm(y.t())) # и опять матричное умножение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1610, -0.6154,  0.4468],\n",
       "        [-0.6242,  0.0245, -0.8571],\n",
       "        [ 1.5801, -0.8821, -0.7437],\n",
       "        [ 0.4104, -0.7644, -0.3790],\n",
       "        [-0.5324, -0.1660, -0.9890]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 3])\n",
      "torch.Size([5, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x.unsqueeze(0).shape) # добавили измерение в начало, аналог броадкастинга \n",
    "print(x.unsqueeze(1).shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1610, -0.6154,  0.4468],\n",
       "         [-0.6242,  0.0245, -0.8571],\n",
       "         [ 1.5801, -0.8821, -0.7437],\n",
       "         [ 0.4104, -0.7644, -0.3790],\n",
       "         [-0.5324, -0.1660, -0.9890]]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x.unsqueeze(0).squeeze(0).shape) # убрали измерение в начале, аналог броадкастинга "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы также можем делать обычные срезы и переводить матрицы назад в numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "a = np.ones((3, 5))\n",
    "x = torch.ones((3, 5))\n",
    "print(np.allclose(x.numpy(), a))\n",
    "print(np.allclose(x.numpy()[:, 1], a[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5058e-01, 9.8086e-01, 8.4747e-01],\n",
      "        [9.0000e-01, 2.1007e-01, 9.5451e-01],\n",
      "        [6.6579e-01, 8.7320e-01, 9.3886e-01],\n",
      "        [8.6527e-01, 4.6251e-01, 3.9762e-04],\n",
      "        [7.3138e-01, 8.8506e-01, 4.0002e-01]], grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "grad can be implicitly created only for scalar outputs",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-f3239ac52453>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \"\"\"\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[0mgrad_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m     \u001b[0mgrad_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[1;34m(outputs, grads)\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m                 \u001b[0mnew_grads\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
     ]
    }
   ],
   "source": [
    "y = torch.rand(5, 3, requires_grad=True)\n",
    "y = y * 1\n",
    "print(y)\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Работаем с градиентами руками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "plt.scatter(boston.data[:, -1], boston.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В pytorch есть возможность при создании тензора указывать нужно ли считать по нему градиент или нет, с помощью параметра `requires_grad`. Когда `requires_grad=True` мы сообщаем фреймворку, о том, что мы хотим следить за всеми тензорами, которые получаются из созданного. Иными словами, у любого тензора, у которого указан данный параметр, будет доступ к цепочке операций и преобразований совершенными с ними. Если эти функции дифференцируемые, то у тензора появляется параметр `.grad`, в котором хранится значение градиента.\n",
    "\n",
    "<img src=\"./example1.png\">\n",
    "\n",
    "Если к результирующему тензору применить метод `.backward()`, то фреймворк посчитает по цепочке градиенту для всех тензоров, у которых `requires_grad=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.tensor([3.], requires_grad=True)\n",
    "b = torch.tensor([1.], requires_grad=True)\n",
    "\n",
    "x = torch.tensor([8], dtype=torch.float32)\n",
    "y = torch.tensor([1], dtype=torch.float32)\n",
    "\n",
    "assert w.grad is None\n",
    "assert b.grad is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (w * w) * x + b # и опять совершаем операции с тензорами\n",
    "loss = y_pred.mean()\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert w.grad is not None # сделали операции и посчитали градиенты, значение должно было появится\n",
    "assert b.grad is not None\n",
    "\n",
    "print(\"dL/dw = \\n\", w.grad)\n",
    "print(\"dL/db = \\n\", b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.rand(1, requires_grad=True)\n",
    "b = torch.rand(1, requires_grad=True)\n",
    "\n",
    "x = torch.tensor(boston.data[:, -1] / boston.data[:, -1].max(), dtype=torch.float32)\n",
    "y = torch.tensor(boston.target, dtype=torch.float32)\n",
    "\n",
    "assert w.grad is None # только создали тензоры и в них нет градиентов\n",
    "assert b.grad is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = w * x + b # и опять совершаем операции с тензорами\n",
    "loss = torch.mean((y_pred - y)**2) # совершаем операции с тензорами\n",
    "loss.backward() # считаем градиенты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert w.grad is not None # сделали операции и посчитали градиенты, значение должно было появится\n",
    "assert b.grad is not None\n",
    "\n",
    "print(\"dL/dw = \\n\", w.grad)\n",
    "print(\"dL/db = \\n\", b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "for i in range(400):\n",
    "\n",
    "    y_pred = w * x + b\n",
    "    # попробуйте сделать полиномиальную регрессию в данном предсказании и посчитать градиенты после\n",
    "    loss = torch.mean((y_pred - y)**2)\n",
    "    loss.backward()\n",
    "\n",
    "    # делаем шаг градиентного спуска с lr = .05\n",
    "    w.data -= 0.05 * w.grad.data \n",
    "    b.data -= 0.05 * b.grad.data\n",
    "\n",
    "    # обнуляем градиенты, чтобы на следующем шаге опять посчитать и не аккумулировать их\n",
    "    w.grad.data.zero_()\n",
    "    b.grad.data.zero_()\n",
    "\n",
    "    # рисуем картинки\n",
    "    if (i+1) % 5 == 0:\n",
    "        clear_output(True)\n",
    "        plt.scatter(x.data.numpy(), y.data.numpy())\n",
    "        plt.scatter(x.data.numpy(), y_pred.data.numpy(),\n",
    "                    color='orange', linewidth=5)\n",
    "        plt.show()\n",
    "\n",
    "        print(\"loss = \", loss.data.numpy())\n",
    "        if loss.data.numpy() < 0.5:\n",
    "            print(\"Done!\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Моя первая нейросеть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы разобраться как обучать нейросите в pytorch, нужно освоить три вещи: \n",
    "\n",
    "1. Как формировать батчи и пихать их в сетку\n",
    "2. Как сделать сетку\n",
    "3. Как написать цикл обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Как формировать батчи и пихать их в сетку\n",
    "\n",
    "Чтобы в данном фреймворке иметь возможность итерироваться по данным и применять к ним преобразования, например, аугментации, о которых вы узнаете позже -- нужно создать свой класс унаследованный от `torch.utils.data.Dataset`.\n",
    "\n",
    "Вот пример из документации:\n",
    "\n",
    "```\n",
    "class FaceLandmarksDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.landmarks_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.landmarks_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.landmarks_frame.iloc[idx, 0])\n",
    "        image = io.imread(img_name)\n",
    "        landmarks = self.landmarks_frame.iloc[idx, 1:]\n",
    "        landmarks = np.array([landmarks])\n",
    "        landmarks = landmarks.astype('float').reshape(-1, 2)\n",
    "        sample = {'image': image, 'landmarks': landmarks}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "```\n",
    "\n",
    "Как вы видите, у такого класса должно быть два метода: \n",
    "\n",
    "* `__len__` -- возвращает информацию о том, сколько объектов у нас в датасете\n",
    "* `__getitem__` -- возвращает семпл и таргет к нему\n",
    "\n",
    "\n",
    "Теперь давайте напишем такой сами, в качестве датасета сгенерируем рандомные данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Our random dataset\n",
    "    x.shape = (N, d), where N = number of examples, and d = number of features\n",
    "    y.shape = (N, )\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, x, y):\n",
    "        \n",
    "        self.x=x\n",
    "        self.y=y\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Эта функция должна возвращать словарь с одним элементом из выборки и ответом\n",
    "        Не забудьте преобразовать пример в формат тензора\n",
    "        \"\"\"\n",
    "        \n",
    "        return {'sample': torch.tensor(self.x[idx, :], dtype=torch.float), 'target': self.y[idx]}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(1000, 5)\n",
    "y = np.random.rand(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_dataset = RandomDataset(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sample': tensor([0.0120, 0.2029, 0.4154, 0.1247, 0.6484]),\n",
       " 'target': 0.14257104841124268}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_dataset.__getitem__(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы из данных получать батчи в pytorch используется такая сущность как даталоадер, который принимает на вход класс унаследованный от `torch.utils.data.Dataset`. Сейчас посмотрим на пример:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(our_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Работают с ним следующим образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: tensor([[0.5772, 0.3261, 0.8307, 0.2790, 0.7472],\n",
      "        [0.0120, 0.2029, 0.4154, 0.1247, 0.6484],\n",
      "        [0.5084, 0.8468, 0.9783, 0.8721, 0.0855],\n",
      "        [0.7812, 0.5008, 0.1813, 0.4601, 0.9599],\n",
      "        [0.3107, 0.2531, 0.3446, 0.4683, 0.3872],\n",
      "        [0.8693, 0.1462, 0.8121, 0.1758, 0.6102],\n",
      "        [0.4488, 0.7782, 0.4241, 0.4613, 0.2195],\n",
      "        [0.9433, 0.5364, 0.9503, 0.3645, 0.5004],\n",
      "        [0.8479, 0.2840, 0.4562, 0.5625, 0.5435],\n",
      "        [0.6951, 0.8011, 0.5778, 0.0160, 0.7419],\n",
      "        [0.2121, 0.6015, 0.5480, 0.3030, 0.5352],\n",
      "        [0.5027, 0.3374, 0.1641, 0.9939, 0.2380],\n",
      "        [0.3656, 0.2899, 0.8094, 0.1789, 0.9058],\n",
      "        [0.2622, 0.9202, 0.7641, 0.5405, 0.1921],\n",
      "        [0.0788, 0.5734, 0.5420, 0.8645, 0.5122],\n",
      "        [0.9589, 0.3145, 0.6386, 0.4095, 0.5082],\n",
      "        [0.0379, 0.9460, 0.9629, 0.5416, 0.9599],\n",
      "        [0.8811, 0.9779, 0.8440, 0.1929, 0.0042],\n",
      "        [0.8880, 0.9577, 0.7380, 0.4815, 0.7442],\n",
      "        [0.4655, 0.0499, 0.8955, 0.5313, 0.4385],\n",
      "        [0.9964, 0.5176, 0.4460, 0.0907, 0.0438],\n",
      "        [0.5955, 0.3114, 0.7075, 0.5541, 0.6617],\n",
      "        [0.1901, 0.4203, 0.3025, 0.8337, 0.7075],\n",
      "        [0.9449, 0.5631, 0.3202, 0.3452, 0.4774],\n",
      "        [0.0456, 0.1206, 0.2855, 0.6970, 0.8453],\n",
      "        [0.2943, 0.8303, 0.8606, 0.1268, 0.7460],\n",
      "        [0.6539, 0.0988, 0.4710, 0.0723, 0.7092],\n",
      "        [0.3959, 0.5505, 0.7333, 0.9401, 0.5718],\n",
      "        [0.9163, 0.9634, 0.2495, 0.1987, 0.8259],\n",
      "        [0.3300, 0.1195, 0.3098, 0.4284, 0.4538],\n",
      "        [0.2660, 0.5191, 0.9679, 0.4224, 0.7748],\n",
      "        [0.4854, 0.1857, 0.7187, 0.5122, 0.6677]])\n",
      "Target: tensor([0.1660, 0.1426, 0.6465, 0.6617, 0.2859, 0.4784, 0.3032, 0.9387, 0.5898,\n",
      "        0.4017, 0.3062, 0.3475, 0.7738, 0.4786, 0.6764, 0.8648, 0.0945, 0.1361,\n",
      "        0.0514, 0.0826, 0.0362, 0.2987, 0.1708, 0.1167, 0.6876, 0.5037, 0.0824,\n",
      "        0.5698, 0.6792, 0.9683, 0.3243, 0.6899], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    batch_x = batch['sample']\n",
    "    batch_y = batch['target']\n",
    "    break\n",
    "print('Sample:', batch_x)\n",
    "print('Target:', batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(our_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Как сделать сетку"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Для того, чтобы в high-level pytorch создавать нейросети используется модуль `nn`. Нейросеть должна быть унаследована от класса `nn.Module`. Пример как это может выглядеть:\n",
    "\n",
    "```\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5)\n",
    "        self.conv2 = nn.Conv2d(20, 20, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "       x = F.relu(self.conv1(x))\n",
    "       return F.relu(self.conv2(x))\n",
    "```\n",
    "\n",
    "Как мы видим на данном примере, у данного класса должно быть метод `forward`, который определяет прямой проход нейросети. Также из класса выше видно, что модуль `nn` содержит в себе реализацию большинства слоев, а модуль `nn.functional` -- функций активаций.\n",
    "\n",
    "Есть еще один способ создать нейросеть и давайте его разберем на практике:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential() # создаем пустую модель, в которую будем добавлять слои\n",
    "model.add_module('l1', nn.Linear(5, 3)) # добавили слой с 5-ю нейронами на вход и 3-мя на выход\n",
    "model.add_module('l2', nn.ReLU()) # добавили функцию активации\n",
    "model.add_module('l3', nn.Linear(3, 1)) # добавили слой с 3-мя нейронами на вход и 5-ю на выход"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = model(batch_x) # получили предсказания модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8.6360e-15, 4.9667e-17, 3.7622e-17, 1.5918e-12, 1.0726e-06, 1.5480e-12,\n",
       "         1.0446e-19, 4.1395e-07, 3.6943e-10, 1.0000e+00],\n",
       "        [6.1903e-17, 1.8034e-14, 1.4278e-10, 2.3015e-13, 1.1762e-14, 1.6562e-14,\n",
       "         1.0000e+00, 3.3341e-27, 5.0807e-13, 5.0806e-23],\n",
       "        [2.0712e-16, 1.0000e+00, 6.0619e-12, 2.5157e-06, 5.5100e-09, 3.6759e-08,\n",
       "         2.9369e-09, 2.4632e-08, 1.6580e-06, 5.3858e-08],\n",
       "        [4.0979e-10, 6.0099e-15, 9.8199e-08, 1.5668e-14, 3.1619e-10, 1.5470e-08,\n",
       "         1.0000e+00, 2.7988e-22, 1.0929e-11, 3.1904e-15]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Как написать цикл обучения\n",
    " \n",
    "Давайте теперь соберем теперь загрузку данных, создание модели и обучим на уже созданном для нас датасете MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./mnist/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d29e60eb8d20432c8347ead55330e568",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting ./mnist/MNIST\\raw\\train-images-idx3-ubyte.gz to ./mnist/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./mnist/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c382ff1545c4143951811d51f28a9fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting ./mnist/MNIST\\raw\\train-labels-idx1-ubyte.gz to ./mnist/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./mnist/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3955791219314a3dad42c26334ff577f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting ./mnist/MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./mnist/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./mnist/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2248a59eaa214ad1a24637711d4f8f1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting ./mnist/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./mnist/MNIST\\raw\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\torchvision\\datasets\\mnist.py:469: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "mnist_train = torchvision.datasets.MNIST(\n",
    "    './mnist/', train=True, download=True, \n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ") # используем готовый класс от торча для загрузки данных для тренировки\n",
    "mnist_val = torchvision.datasets.MNIST(\n",
    "    './mnist/', train=False, download=True,\n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ") # используем готовый класс от торча для загрузки данных для валидации\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    mnist_train, batch_size=4, shuffle=True, num_workers=1\n",
    ") # так как это уже унаследованный от Dataset класс, его можно сразу пихать в даталоадер\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    mnist_val, batch_size=4, shuffle=True, num_workers=1\n",
    ") # так как это уже унаследованный от Dataset класс, его можно сразу пихать в даталоадер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in [0, 1]:\n",
    "    plt.subplot(1, 2, i + 1)\n",
    "    plt.imshow(mnist_train[i][0].squeeze(0).numpy().reshape([28, 28]))\n",
    "    plt.title(str(mnist_train[i][1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Flatten(), # превращаем картинку 28х28 в вектор размером 784\n",
    "    nn.Linear(784, 128), # входной слой размером 784 нейронов с выходом в 128 нейронов\n",
    "    nn.ReLU(), # функция активации релу\n",
    "    nn.Linear(128, 10), # функция активации релу\n",
    "    nn.Softmax(dim=-1) # софтмакс для получения вероятностного распределения над метками класса\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.05) # создаем оптимизатор и передаем туда параметры модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Веса моделей хранятся в виде матриц и выглядят так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "[x for x in model.named_parameters()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "for epoch in range(0, 11): # всего у нас будет 10 эпох (10 раз подряд пройдемся по всем батчам из трейна)\n",
    "    for x_train, y_train in tqdm(train_dataloader): # берем батч из трейн лоадера\n",
    "        y_pred = model(x_train) # делаем предсказания\n",
    "        loss = nn.CrossEntropyLoss()(y_pred, y_train) # считаем лосс\n",
    "        loss.backward() # считаем градиенты обратным проходом\n",
    "        optimizer.step() # обновляем параметры сети\n",
    "        optimizer.zero_grad() # обнуляем посчитанные градиенты параметров\n",
    "    \n",
    "    if epoch % 2 == 0:\n",
    "        mean_val_loss = [] # сюда будем складывать средний лосс по батчам\n",
    "        val_accuracy = []\n",
    "        with torch.no_grad(): # мы считаем качество, поэтому мы запрещаем фреймворку считать градиенты по параметрам\n",
    "            for x_val, y_val in tqdm(val_dataloader): # берем батч из вал лоадера\n",
    "                y_pred = model(x_val) # делаем предсказания\n",
    "                loss = nn.CrossEntropyLoss()(y_pred, y_val) # считаем лосс\n",
    "                mean_val_loss.append(loss.numpy()) # добавляем в массив \n",
    "                val_accuracy.extend((torch.argmax(y_pred, dim=-1) == y_val).numpy().tolist())\n",
    "        print('Epoch: {epoch}, loss: {loss}, accuracy: {accuracy}'.format(\n",
    "                epoch=epoch, loss=np.mean(mean_val_loss), accuracy=np.mean(val_accuracy)\n",
    "        )) # выводим статистику\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1.weight', Parameter containing:\n",
       "  tensor([[ 0.0308,  0.0137, -0.0008,  ...,  0.0181,  0.0195,  0.0070],\n",
       "          [ 0.0247, -0.0180, -0.0239,  ..., -0.0166,  0.0190, -0.0270],\n",
       "          [ 0.0097,  0.0313, -0.0197,  ..., -0.0295, -0.0132, -0.0186],\n",
       "          ...,\n",
       "          [-0.0206,  0.0235, -0.0271,  ..., -0.0127,  0.0216, -0.0001],\n",
       "          [-0.0165,  0.0210, -0.0343,  ..., -0.0126, -0.0304, -0.0069],\n",
       "          [-0.0248, -0.0348, -0.0282,  ...,  0.0124,  0.0289,  0.0037]],\n",
       "         requires_grad=True)), ('1.bias', Parameter containing:\n",
       "  tensor([ 0.0306, -0.0150, -0.0072,  0.0356,  0.0216,  0.0048,  0.0308, -0.0130,\n",
       "           0.0200, -0.0216,  0.0089,  0.0076,  0.0231,  0.0207,  0.0186, -0.0149,\n",
       "          -0.0161, -0.0219, -0.0047,  0.0225, -0.0303,  0.0268,  0.0325, -0.0235,\n",
       "          -0.0030, -0.0340,  0.0057, -0.0323, -0.0140, -0.0187, -0.0036,  0.0341,\n",
       "           0.0054,  0.0185, -0.0225, -0.0219, -0.0139, -0.0222,  0.0028, -0.0170,\n",
       "           0.0082,  0.0252, -0.0228,  0.0315, -0.0245,  0.0004, -0.0272, -0.0226,\n",
       "           0.0081,  0.0129, -0.0127,  0.0144, -0.0128, -0.0244, -0.0323,  0.0090,\n",
       "          -0.0236, -0.0100, -0.0312, -0.0137, -0.0011,  0.0093, -0.0187,  0.0220,\n",
       "          -0.0281, -0.0197, -0.0048, -0.0059,  0.0209, -0.0044, -0.0008,  0.0158,\n",
       "          -0.0079,  0.0007, -0.0036,  0.0152, -0.0112, -0.0280, -0.0285, -0.0272,\n",
       "          -0.0129, -0.0096, -0.0006, -0.0251,  0.0059,  0.0110,  0.0003,  0.0337,\n",
       "          -0.0158, -0.0049,  0.0150, -0.0150, -0.0278, -0.0201, -0.0029, -0.0047,\n",
       "          -0.0185,  0.0214,  0.0263,  0.0232,  0.0289, -0.0070,  0.0048,  0.0038,\n",
       "           0.0226,  0.0191, -0.0063, -0.0066, -0.0237, -0.0053,  0.0029, -0.0070,\n",
       "          -0.0083, -0.0211, -0.0056, -0.0295, -0.0116,  0.0214, -0.0337,  0.0119,\n",
       "          -0.0290,  0.0228, -0.0340, -0.0190, -0.0105, -0.0293, -0.0114,  0.0224],\n",
       "         requires_grad=True)), ('3.weight', Parameter containing:\n",
       "  tensor([[-0.0476,  0.0302,  0.0719,  ..., -0.0722, -0.0721,  0.0082],\n",
       "          [-0.0002, -0.0663, -0.0048,  ...,  0.0117, -0.0142,  0.0342],\n",
       "          [ 0.0239,  0.0574, -0.0833,  ..., -0.0258, -0.0548,  0.0096],\n",
       "          ...,\n",
       "          [-0.0655,  0.0515, -0.0336,  ..., -0.0028, -0.0190, -0.0564],\n",
       "          [-0.0400,  0.0521,  0.0202,  ..., -0.0103,  0.0872,  0.0455],\n",
       "          [ 0.0707, -0.0745, -0.0729,  ...,  0.0583, -0.0737, -0.0055]],\n",
       "         requires_grad=True)), ('3.bias', Parameter containing:\n",
       "  tensor([-0.0460,  0.0758,  0.0514, -0.0366,  0.0076, -0.0025,  0.0881,  0.0416,\n",
       "          -0.0414,  0.0484], requires_grad=True))]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Дополнительные материалы:\n",
    "\n",
    "* [Хорошая книга про pytorch](https://pytorch.org/assets/deep-learning/Deep-Learning-with-PyTorch.pdf)\n",
    "* [Использование pytorch на GPU](https://pytorch.org/docs/master/notes/cuda.html)\n",
    "* [Pytorch за 60 минут](http://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)\n",
    "* [Как устроено автоматическое дифференцирование в pytorch](http://videolectures.net/site/normal_dl/tag=1129745/deeplearning2017_johnson_automatic_differentiation_01.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 15000/15000 [00:10<00:00, 1380.69it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2500/2500 [00:02<00:00, 1163.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 1.5358483791351318, accuracy: 0.9313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 15000/15000 [00:10<00:00, 1416.59it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 15000/15000 [00:10<00:00, 1414.97it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2500/2500 [00:02<00:00, 1158.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, loss: 1.5095382928848267, accuracy: 0.9533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 15000/15000 [00:10<00:00, 1413.71it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 15000/15000 [00:10<00:00, 1413.95it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2500/2500 [00:02<00:00, 1163.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, loss: 1.498794674873352, accuracy: 0.9645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 15000/15000 [00:10<00:00, 1421.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 15000/15000 [00:10<00:00, 1398.68it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2500/2500 [00:02<00:00, 1173.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, loss: 1.494233250617981, accuracy: 0.9683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 15000/15000 [00:10<00:00, 1419.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 15000/15000 [00:10<00:00, 1405.81it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2500/2500 [00:02<00:00, 1172.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, loss: 1.4920300245285034, accuracy: 0.9718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 15000/15000 [00:10<00:00, 1399.95it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 15000/15000 [00:10<00:00, 1415.61it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2500/2500 [00:02<00:00, 1180.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, loss: 1.48988938331604, accuracy: 0.9727\n"
     ]
    }
   ],
   "source": [
    "epoch = 0\n",
    "for epoch in range(0, 11): # всего у нас будет 10 эпох (10 раз подряд пройдемся по всем батчам из трейна)\n",
    "    for x_train, y_train in tqdm(train_dataloader): # берем батч из трейн лоадера\n",
    "        y_pred = model(x_train) # делаем предсказания\n",
    "        loss = nn.CrossEntropyLoss()(y_pred, y_train) # считаем лосс\n",
    "        loss.backward() # считаем градиенты обратным проходом\n",
    "        optimizer.step() # обновляем параметры сети\n",
    "        optimizer.zero_grad() # обнуляем посчитанные градиенты параметров\n",
    "    \n",
    "    if epoch % 2 == 0:\n",
    "        mean_val_loss = [] # сюда будем складывать средний лосс по батчам\n",
    "        val_accuracy = []\n",
    "        with torch.no_grad(): # мы считаем качество, поэтому мы запрещаем фреймворку считать градиенты по параметрам\n",
    "            for x_val, y_val in tqdm(val_dataloader): # берем батч из вал лоадера\n",
    "                y_pred = model(x_val) # делаем предсказания\n",
    "                loss = nn.CrossEntropyLoss()(y_pred, y_val) # считаем лосс\n",
    "                mean_val_loss.append(loss.numpy()) # добавляем в массив \n",
    "                val_accuracy.extend((torch.argmax(y_pred, dim=-1) == y_val).numpy().tolist())\n",
    "        print('Epoch: {epoch}, loss: {loss}, accuracy: {accuracy}'.format(\n",
    "                epoch=epoch, loss=np.mean(mean_val_loss), accuracy=np.mean(val_accuracy)\n",
    "        )) # выводим статистику\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дополнительные материалы:\n",
    "\n",
    "* [Хорошая книга про pytorch](https://pytorch.org/assets/deep-learning/Deep-Learning-with-PyTorch.pdf)\n",
    "* [Использование pytorch на GPU](https://pytorch.org/docs/master/notes/cuda.html)\n",
    "* [Pytorch за 60 минут](http://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)\n",
    "* [Как устроено автоматическое дифференцирование в pytorch](http://videolectures.net/site/normal_dl/tag=1129745/deeplearning2017_johnson_automatic_differentiation_01.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
